{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Reason for Exam: CHRONIC LOWER BACK PAIN.  GET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Reason for Exam: KNOWN MULTILEVEL DEGENERATIVE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>MR LUMBAR SPINE    Reason for Exam: PROGRESSIV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>MR CERVICAL SPINE    Reason for Exam: HAS HX O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>MRI lumbar spine     Comparison: No prior     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id  label                                               text\n",
       "0         2      0  Reason for Exam: CHRONIC LOWER BACK PAIN.  GET...\n",
       "1         3      0  Reason for Exam: KNOWN MULTILEVEL DEGENERATIVE...\n",
       "2         4      0  MR LUMBAR SPINE    Reason for Exam: PROGRESSIV...\n",
       "3         5      0  MR CERVICAL SPINE    Reason for Exam: HAS HX O...\n",
       "4         6      0  MRI lumbar spine     Comparison: No prior     ..."
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"KEC_SAC_radiology_data_for_CS_8.3.2022.csv\"\n",
    "data = pd.read_csv(data_path, header=0, names=[\"study_id\", \"label\", \"text\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "* Remove numbers (such as years and dates) but keep alphanumerics (t1, t5, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def replace(string):\n",
    "#     return re.sub(r'\\b[\\d]+\\b', '',string)\n",
    "\n",
    "# data['text'] = data['text'].apply(replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Unigrams\n",
    "* Lowercase all words (distinction between uppercase and lowercase is not important)\n",
    "* Remove words that occur in more 90% of training texts (hopefully removes stop words such as 'a' and 'the' that don't provide much meaning)\n",
    "* Remove words that occur in less than 1% training texts (easy way to remove mispelled words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Accuracy -> 0.8400\n",
      "F1-Score -> 0.2500\n",
      "Precision -> 0.2500\n",
      "Recall -> 0.2500\n",
      "Fold 2\n",
      "Accuracy -> 0.8514\n",
      "F1-Score -> 0.1538\n",
      "Precision -> 0.1429\n",
      "Recall -> 0.1667\n",
      "Fold 3\n",
      "Accuracy -> 0.7973\n",
      "F1-Score -> 0.4000\n",
      "Precision -> 0.2941\n",
      "Recall -> 0.6250\n",
      "Fold 4\n",
      "Accuracy -> 0.7838\n",
      "F1-Score -> 0.3333\n",
      "Precision -> 0.2857\n",
      "Recall -> 0.4000\n",
      "Fold 5\n",
      "Accuracy -> 0.7703\n",
      "F1-Score -> 0.2609\n",
      "Precision -> 0.2308\n",
      "Recall -> 0.3000\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "fold = 0\n",
    "\n",
    "accuracy = 0\n",
    "f1 = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "\n",
    "folds = KFold(n_splits=k, random_state=random_state, shuffle=True)\n",
    "\n",
    "for train_index, test_index in folds.split(data['text'], data['label']):\n",
    "    fold += 1\n",
    "    X_train, Y_train = data['text'][train_index], data['label'][train_index]\n",
    "    X_test, Y_test = data['text'][test_index], data['label'][test_index]\n",
    "    \n",
    "    vectorizer = CountVectorizer(lowercase=True, max_df=0.90, min_df=0.01)\n",
    "\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    \n",
    "    lr = LogisticRegression(penalty='l1', solver='liblinear', C=0.16, random_state=random_state, class_weight='balanced')\n",
    "    SVM = SVC(C=9, kernel='linear', degree=3, gamma='auto')\n",
    "    \n",
    "    ensemble = VotingClassifier(estimators=[('lr', lr), ('svm', SVM)], voting='hard')\n",
    "    ensemble.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = ensemble.predict(X_test)\n",
    "    \n",
    "    accuracy += accuracy_score(Y_pred, Y_test)/k\n",
    "    f1 += f1_score(Y_pred, Y_test)/k\n",
    "    precision += precision_score(Y_pred, Y_test)/k\n",
    "    recall += recall_score(Y_pred, Y_test)/k\n",
    "    \n",
    "    print(f\"Fold {fold}\")\n",
    "    print(f\"Accuracy -> {accuracy_score(Y_pred, Y_test):0.4f}\")\n",
    "    print(f\"F1-Score -> {f1_score(Y_pred, Y_test):0.4f}\")\n",
    "    print(f\"Precision -> {precision_score(Y_pred, Y_test):0.4f}\")\n",
    "    print(f\"Recall -> {recall_score(Y_pred, Y_test):0.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -> 0.8085\n",
      "F1-Score -> 0.2796\n",
      "Precision -> 0.2407\n",
      "Recall -> 0.3483\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy -> {accuracy:0.4f}\")\n",
    "print(f\"F1-Score -> {f1:0.4f}\")\n",
    "print(f\"Precision -> {precision:0.4f}\")\n",
    "print(f\"Recall -> {recall:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Unigrams\n",
    "* Lowercase all words (distinction between uppercase and lowercase is not important)\n",
    "* Remove words that occur in more 90% of training texts (hopefully removes stop words such as 'a' and 'the' that don't provide much meaning)\n",
    "* Remove words that occur in less than 1% training texts (easy way to remove mispelled words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Accuracy -> 0.8800\n",
      "F1-Score -> 0.3077\n",
      "Precision -> 0.2500\n",
      "Recall -> 0.4000\n",
      "Fold 2\n",
      "Accuracy -> 0.8649\n",
      "F1-Score -> 0.2857\n",
      "Precision -> 0.2857\n",
      "Recall -> 0.2857\n",
      "Fold 3\n",
      "Accuracy -> 0.7838\n",
      "F1-Score -> 0.2727\n",
      "Precision -> 0.1765\n",
      "Recall -> 0.6000\n",
      "Fold 4\n",
      "Accuracy -> 0.8108\n",
      "F1-Score -> 0.3636\n",
      "Precision -> 0.2857\n",
      "Recall -> 0.5000\n",
      "Fold 5\n",
      "Accuracy -> 0.8108\n",
      "F1-Score -> 0.3636\n",
      "Precision -> 0.3077\n",
      "Recall -> 0.4444\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "fold = 0\n",
    "\n",
    "accuracy = 0\n",
    "f1 = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "\n",
    "folds = KFold(n_splits=k, random_state=random_state, shuffle=True)\n",
    "\n",
    "for train_index, test_index in folds.split(data['text'], data['label']):\n",
    "    fold += 1\n",
    "    X_train, Y_train = data['text'][train_index], data['label'][train_index]\n",
    "    X_test, Y_test = data['text'][test_index], data['label'][test_index]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(lowercase=True, max_df=0.90, min_df=0.01)\n",
    "\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    \n",
    "    lr = LogisticRegression(random_state=random_state, class_weight='balanced')\n",
    "    SVM = SVC(C=9, kernel='linear', degree=3, gamma='auto')\n",
    "    \n",
    "    ensemble = VotingClassifier(estimators=[('lr', lr), ('svm', SVM)], voting='hard')\n",
    "    ensemble.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = ensemble.predict(X_test)\n",
    "    \n",
    "    accuracy += accuracy_score(Y_pred, Y_test)/k\n",
    "    f1 += f1_score(Y_pred, Y_test)/k\n",
    "    precision += precision_score(Y_pred, Y_test)/k\n",
    "    recall += recall_score(Y_pred, Y_test)/k\n",
    "    \n",
    "    print(f\"Fold {fold}\")\n",
    "    print(f\"Accuracy -> {accuracy_score(Y_pred, Y_test):0.4f}\")\n",
    "    print(f\"F1-Score -> {f1_score(Y_pred, Y_test):0.4f}\")\n",
    "    print(f\"Precision -> {precision_score(Y_pred, Y_test):0.4f}\")\n",
    "    print(f\"Recall -> {recall_score(Y_pred, Y_test):0.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -> 0.8301\n",
      "F1-Score -> 0.3187\n",
      "Precision -> 0.2611\n",
      "Recall -> 0.4460\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy -> {accuracy:0.4f}\")\n",
    "print(f\"F1-Score -> {f1:0.4f}\")\n",
    "print(f\"Precision -> {precision:0.4f}\")\n",
    "print(f\"Recall -> {recall:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Unigrams + Bigrams\n",
    "* Lowercase all words (distinction between uppercase and lowercase is not important)\n",
    "* Remove words that occur in more 90% of training texts (hopefully removes stop words such as 'a' and 'the' that don't provide much meaning)\n",
    "* Remove words that occur in less than 1% training texts (easy way to remove mispelled words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Accuracy -> 0.8400\n",
      "F1-Score -> 0.2500\n",
      "Precision -> 0.2500\n",
      "Recall -> 0.2500\n",
      "Fold 2\n",
      "Accuracy -> 0.8649\n",
      "F1-Score -> 0.0000\n",
      "Precision -> 0.0000\n",
      "Recall -> 0.0000\n",
      "Fold 3\n",
      "Accuracy -> 0.8108\n",
      "F1-Score -> 0.3636\n",
      "Precision -> 0.2353\n",
      "Recall -> 0.8000\n",
      "Fold 4\n",
      "Accuracy -> 0.7838\n",
      "F1-Score -> 0.2000\n",
      "Precision -> 0.1429\n",
      "Recall -> 0.3333\n",
      "Fold 5\n",
      "Accuracy -> 0.8243\n",
      "F1-Score -> 0.2353\n",
      "Precision -> 0.1538\n",
      "Recall -> 0.5000\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "fold = 0\n",
    "\n",
    "accuracy = 0\n",
    "f1 = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "\n",
    "folds = KFold(n_splits=k, random_state=random_state, shuffle=True)\n",
    "\n",
    "for train_index, test_index in folds.split(data['text'], data['label']):\n",
    "    fold += 1\n",
    "    X_train, Y_train = data['text'][train_index], data['label'][train_index]\n",
    "    X_test, Y_test = data['text'][test_index], data['label'][test_index]\n",
    "    \n",
    "    vectorizer = CountVectorizer(ngram_range = [1, 2], lowercase=True, max_df=0.90, min_df=0.01)\n",
    "\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    \n",
    "    lr = LogisticRegression(penalty='l1', solver='liblinear', C=0.16, random_state=random_state, class_weight='balanced')\n",
    "    SVM = SVC(C=9, kernel='linear', degree=3, gamma='auto')\n",
    "    \n",
    "    ensemble = VotingClassifier(estimators=[('lr', lr), ('svm', SVM)], voting='hard')\n",
    "    ensemble.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = ensemble.predict(X_test)\n",
    "    \n",
    "    accuracy += accuracy_score(Y_pred, Y_test)/k\n",
    "    f1 += f1_score(Y_pred, Y_test)/k\n",
    "    precision += precision_score(Y_pred, Y_test)/k\n",
    "    recall += recall_score(Y_pred, Y_test)/k\n",
    "    \n",
    "    print(f\"Fold {fold}\")\n",
    "    print(f\"Accuracy -> {accuracy_score(Y_pred, Y_test):0.4f}\")\n",
    "    print(f\"F1-Score -> {f1_score(Y_pred, Y_test):0.4f}\")\n",
    "    print(f\"Precision -> {precision_score(Y_pred, Y_test):0.4f}\")\n",
    "    print(f\"Recall -> {recall_score(Y_pred, Y_test):0.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -> 0.8248\n",
      "F1-Score -> 0.2098\n",
      "Precision -> 0.1564\n",
      "Recall -> 0.3767\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy -> {accuracy:0.4f}\")\n",
    "print(f\"F1-Score -> {f1:0.4f}\")\n",
    "print(f\"Precision -> {precision:0.4f}\")\n",
    "print(f\"Recall -> {recall:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Unigrams + Bigrams\n",
    "* Lowercase all words (distinction between uppercase and lowercase is not important)\n",
    "* Remove words that occur in more 90% of training texts (hopefully removes stop words such as 'a' and 'the' that don't provide much meaning)\n",
    "* Remove words that occur in less than 1% training texts (easy way to remove mispelled words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Accuracy -> 0.8667\n",
      "F1-Score -> 0.2857\n",
      "Precision -> 0.2500\n",
      "Recall -> 0.3333\n",
      "Fold 2\n",
      "Accuracy -> 0.8649\n",
      "F1-Score -> 0.1667\n",
      "Precision -> 0.1429\n",
      "Recall -> 0.2000\n",
      "Fold 3\n",
      "Accuracy -> 0.7973\n",
      "F1-Score -> 0.2857\n",
      "Precision -> 0.1765\n",
      "Recall -> 0.7500\n",
      "Fold 4\n",
      "Accuracy -> 0.7973\n",
      "F1-Score -> 0.1176\n",
      "Precision -> 0.0714\n",
      "Recall -> 0.3333\n",
      "Fold 5\n",
      "Accuracy -> 0.8108\n",
      "F1-Score -> 0.1250\n",
      "Precision -> 0.0769\n",
      "Recall -> 0.3333\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "fold = 0\n",
    "\n",
    "accuracy = 0\n",
    "f1 = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "\n",
    "folds = KFold(n_splits=k, random_state=random_state, shuffle=True)\n",
    "\n",
    "for train_index, test_index in folds.split(data['text'], data['label']):\n",
    "    fold += 1\n",
    "    X_train, Y_train = data['text'][train_index], data['label'][train_index]\n",
    "    X_test, Y_test = data['text'][test_index], data['label'][test_index]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(ngram_range=[1,2], lowercase=True, max_df=0.90, min_df=0.01)\n",
    "\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    \n",
    "    lr = LogisticRegression(random_state=random_state, class_weight='balanced')\n",
    "    SVM = SVC(C=9, kernel='linear', degree=3, gamma='auto')\n",
    "    \n",
    "    ensemble = VotingClassifier(estimators=[('lr', lr), ('svm', SVM)], voting='hard')\n",
    "    ensemble.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = ensemble.predict(X_test)\n",
    "    \n",
    "    accuracy += accuracy_score(Y_pred, Y_test)/k\n",
    "    f1 += f1_score(Y_pred, Y_test)/k\n",
    "    precision += precision_score(Y_pred, Y_test)/k\n",
    "    recall += recall_score(Y_pred, Y_test)/k\n",
    "    \n",
    "    print(f\"Fold {fold}\")\n",
    "    print(f\"Accuracy -> {accuracy_score(Y_pred, Y_test):0.4f}\")\n",
    "    print(f\"F1-Score -> {f1_score(Y_pred, Y_test):0.4f}\")\n",
    "    print(f\"Precision -> {precision_score(Y_pred, Y_test):0.4f}\")\n",
    "    print(f\"Recall -> {recall_score(Y_pred, Y_test):0.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -> 0.8274\n",
      "F1-Score -> 0.1961\n",
      "Precision -> 0.1435\n",
      "Recall -> 0.3900\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy -> {accuracy:0.4f}\")\n",
    "print(f\"F1-Score -> {f1:0.4f}\")\n",
    "print(f\"Precision -> {precision:0.4f}\")\n",
    "print(f\"Recall -> {recall:0.4f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
